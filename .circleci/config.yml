# Use the latest 2.1 version of CircleCI pipeline process engine. See: https://circleci.com/docs/2.0/configuration-reference
version: 2.1

commands:
  print_pipeline_id:
    description: Prints Pipeline ID
    parameters:
      parameter_id:
        type: string
        default: "Hello World"
    steps:
      - run: echo << parameters.parameter_id >>
    
  destroy_environment:
    steps:
      - run:
          name: Destroy environment
          when: on_fail
          command: |
              aws cloudformation delete-stack --stack-name prod-${CIRCLE_WORKFLOW_ID}

# Use a package of configuration called an orb.
orbs:
  # Declare a dependency on the welcome-orb
  welcome: circleci/welcome-orb@0.4.1
# Orchestrate or schedule a set of jobs
jobs:
  print_hello:
    docker:
      - image: circleci/node:13.8.0
    steps: 
      - checkout
      - run:
          name: Print Hello 
          command: |
            #!/bin/bash
            chmod +x hello.sh
            ./hello.sh
            return 1
      - run:
          name: Throw Error
          command: |
            echo "Your job has been failed!"
          when: on_fail
            
  print_world:
    docker:
      - image: circleci/node:13.8.0
    steps: 
      - checkout
      - run:
          name: Print World
          command: |
            #!/bin/bash
            chmod +x world.sh
            ./world.sh
  print_myname:
    environment:
      MYNAME: Cansel
    docker:
      - image: circleci/node:13.8.0
    steps: 
      - checkout
      - run: echo $MYNAME
      - print_pipeline_id:
          parameter_id: $CIRCLE_WORKFLOW_ID
      
  save_hello_world_output:
    docker:
      - image: circleci/node:13.8.0
    steps: 
      - run:
          name: Save Hello World Output
          command: |
            echo "Hello World!" > ~/output.txt
      - persist_to_workspace:
          root: ~/
          paths:
            - output.txt
  
  print_output_file:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - attach_workspace:
          at: ~/
      - run:
          name: Read the Output
          command: |
            cat ~/output.txt
  
  create_infrastructure:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Create Stack
          command: |
            aws cloudformation deploy \
              --template-file template.yml \
              --stack-name prod-${CIRCLE_WORKFLOW_ID}
              --parameter-overrides NAME="${CIRCLE_WORKFLOW_ID}"
      - destroy_environment

  create_and_deploy_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Create Stack
          command: |
            aws cloudformation deploy \
            --template-file bucket.yml \
            --stack-name cansel-${CIRCLE_WORKFLOW_ID:0:7} \ 
            --parameter-overrides NAME="cansel-${CIRCLE_WORKFLOW_ID:0:7}"
      - run: aws s3 sync . s3://cansel-${CIRCLE_WORKFLOW_ID} --delete

  get_last_deployment_id:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Get Deployment ID
          command: |
            aws cloudformation \
            list-exports --query "Exports[?Name==\`PipelineID\`].Value" \
            --no-paginate --output text > ~/pipeline_id.txt
      - run:
          name: get last deployment stack name
          command: |
            aws cloudformation \
            list-exports --query "Exports[?Name==\`StackName\`].Value" \
            --no-paginate --output text > ~/stack_name.txt
      - persist_to_workspace:
          root: ~/
          paths:
            - pipeline_id.txt
            - stack_name.txt

  promote_to_production:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Promote to Production
          command: |
            aws cloudformation deploy \
            --template-file cloudformation.yml \
            --stack-name production-distro \
            --parameter-overrides PipelineID="cansel-${CIRCLE_WORKFLOW_ID}"

  clean_up_old_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Clean Up Old Frontend
          command: |
            cat ~/pipeline_id.txt
            cat ~/stack_name.txt
            PreviousPipelineID=$(cat ~/pipeline_id.txt)
            echo $PreviousPipelineID
            PreviousStackName=$(cat ~/stack_name.txt)
            echo $PreviousStackName
            aws s3 rm "s3://${PreviousPipelineID}" --recursive
            aws cloudformation delete-stack --stack-name ${PreviousStackName}

  deploy:
    docker: 
      - image: python:3.7-alpine3.11
    steps:
      - checkout
      - add_ssh_keys:
          fingerprints:
            - "d1:c3:52:06:4c:e8:b4:fd:99:d9:85:cb:61:ee:90:ad"
      - run:
          name: Install dependencies
          command: |
            apk add --update ansible
      - run:
          name: Install flask
          command: |
            pip install flask
      - run:
          name: Configure server
          command: |
            ansible-playbook -i inventory.txt main-remote.yml

  smoke_test:
    docker: 
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Smoke Test for Google
          command: |
            #!/bin/bash
            chmod +x smoke-test.sh
            ./smoke-test.sh
      

workflows:
  cd_workflow:
    jobs:
      #- deploy
      #- welcome/run
      #- print_hello
      #- print_world
      #- print_myname
      #- save_hello_world_output
      #- print_output_file:
       #   requires:
       #     - save_hello_world_output
     # - create_infrastructure:
      #    filters:
       #     branches:
        #      only:
         #       - master
      #- smoke_test
      - create_and_deploy_front_end
      - get_last_deployment_id:
          requires:
            - create_and_deploy_front_end
      - promote_to_production:
          requires:
            - get_last_deployment_id
      - clean_up_old_front_end:
          requires:
            - promote_to_production